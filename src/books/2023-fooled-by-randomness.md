# Fooled by Randomness: The Hidden Role of Chance in Life and in the Markets

This is my summary of "[Fooled by Randomness: The Hidden Role of Chance in Life and in the Markets](https://amzn.to/43rdpVB)" written by Nassim Nicholas Taleb.

-----


1. Behavioral scientists believe that one of the main reasons why people become leaders is not from what skills they seem to possess, but rather from what extremely superficial impression they make on others through hardly perceptible physical signals-what we call today “charisma,” for example.
2. In addition, there seems to be curious evidence of a link between leadership and a form of psychopathology (the sociopath) that encourages the non-blinking, self-confident, insensitive person to rally followers.
3. > Never ask a man if he is from Sparta: If he were, he would have let you know such an important fact — and if he were not, you could hurt his feelings.
4. One cannot consider a profession without taking into account the average of the people who enter it, not the sample of those who have succeeded in it.
5. One cannot judge a performance in any given field (war, politics, medicine, investments) by the results, but by the costs of the alternative (i.e., if history played out differently). Such substitute courses of events are called **alternative histories**.
6. Clearly, the quality of a decision cannot be solely judged based on its outcome, but such a point seems to be voiced only by people who fail (those who succeed attribute their success to the quality of their decision).
7. Mathematics is not just a “numbers game,” it is a way of thinking.
8. Denigration of history: gamblers, investors, and decision-makers feel that the sorts of things that happen to others would not necessarily happen to them.
9. It is foolish to think that an irrational market cannot become even more irrational.
10. In a famous experiment, researchers found that the majority of people, whether predictors or non-predictors, will judge a deadly flood (causing thousands of deaths) caused by a California earthquake to be more likely than a fatal flood (causing thousands of deaths) occurring somewhere in North America (which happens to include California).
11. As a derivatives trader the author noticed that people do not like to insure against something **abstract**; the risk that merits their attention is always something vivid.
12. Both risk detection and risk avoidance are not mediated in the “thinking” part of the brain but largely in the emotional one. The consequences are not trivial: It means that rational thinking has little, very little, to do with risk avoidance. Much of what rational thinking seems to do is rationalize one’s actions by fitting some logic to them.
13. Beware the confusion between **correctness** and **intelligibility**. Part of conventional wisdom favors things that can be explained rather instantly and “in a nutshell” — in many circles, it is considered law.
14. > Common sense is nothing but a collection of misconceptions acquired by age eighteen. — Attributed to Einstein.
15. What sounds intelligent in a conversation or a meeting, or, particularly, in the media, is suspicious.
16. Any reading of the history of science would show that almost all the smart things that have been proven by science appeared like lunacies at the time they were first discovered.
17. From the standpoint of an institution, the existence of a risk manager has less to do with actual risk reduction than it has to do with the impression of risk reduction.
18. **Stochastic processes** refer to the dynamics of events unfolding with time. **Stochastic** is a fancy Greek name for **random**. This branch of probability concerns itself with the study of the evolution of successive random events one could call it the mathematics of history. The key about a process is that it has time in it.
19. People fail to learn that their emotional reactions to past experiences (positive or negative) were short-lived — yet they continuously retain the bias of thinking that the purchase of an object will bring long-lasting happiness or that a setback will cause severe and prolonged distress (when in the past similar setbacks did not affect them for very long and the joy of the purchase was short-lived).
20. Things are always obvious after the fact.
21. When you look at the past, the past will always be deterministic, since only one single observation took place.
22. Psychologists call this overestimation of what one knew at the time of the event due to subsequent information the **hindsight bias**, the “I knew it all along” effect.
23. A mistake is not something to be determined after the fact, but in the light of the information until that point.
24. A more vicious effect of such hindsight bias is that those who are very good at predicting the past will think of themselves as good at predicting the future, and feel confident about their ability to do so.
25. Robert Shiller made his mark with his 1981 paper on the volatility of markets, where he determined that if a stock price is the estimated value of “something” (say the discounted cash flows from a corporation), then market prices are way too volatile in relation to tangible manifestations of that “something” (he used dividends as proxy). Prices swing more than the fundamentals they are supposed to reflect, they visibly overreact by being too high at times (when their price overshoots the good news or when they go up without any marked reason or too low at others.
26. The volatility differential between prices and information meant that something about “rational expectation” did not work. (Prices did not rationally reflect the long-term value of securities and were overshooting in either direction.)
27. Markets had to be wrong. Shiller then pronounced markets to be not as efficient as established by financial theory (efficient markets meant, in a nutshell, that prices should adapt to all available information in such a way as to be totally unpredictable to us humans and prevent people from deriving profits).
28. Journalism goes to what can capture our attention, with adequate sound bites.
29. The wise man listens to meaning; the fool only gets the noise.
30. Performance observed over a narrow time scale is usually just noise.
31. Over a short time increment, one observes the variability of a portfolio, not the returns.
32. The same methodology can explain why the news (the high scale) is full of noise and why history (the low scale) is largely stripped of it (though fraught with interpretation problems.
33. Some psychologists estimate the negative effect for an average loss to be up to 2.5 the magnitude of a positive one.
34. Negative mutations are traits that survive despite being worse, from the reproductive fitness standpoint, than the ones they replaced. However, they cannot be expected to last more than a few generations (under what is called temporal aggregation).
35. Darwinian fitness applies to species developing over a very long time, not observed over a short term — time aggregation eliminates much of the effects of randomness; things (noise) balance out over the long run.
36. Owing to the abrupt rare events, we do not live in a world where things “converge” continuously toward betterment. Nor do things in life move continuously at all.
37. Just as an animal could have survived because its sample path was lucky, the “best” operators in a given business can come from a subset of operators who survived because of over-fitness to a sample path — a sample path that was free of the evolutionary rare event.
38. The frequency or probability of the loss, in and by itself, is totally irrelevant; it needs to be judged in connection with the magnitude of the outcome.
39. It is not how likely an event is to happen that matters, it is how much is made when it happens that should be the consideration.
40. History teaches us that things that never happened before do happen.
41. Rare events are always unexpected, otherwise they would not occur.
42. The economist Robert Lucas dealt a blow to econometrics by arguing that if people were rational then their rationality would cause them to figure out predictable patterns from the past and adapt, so that past information would be completely useless for predicting the future.
43. No amount of observations of white swans can allow the inference that all swans are white, but the observation of a single black swan is sufficient to refute that conclusion.
44. Without a proper method, empirical observations can lead you astray. Rigor needs to be applied in the gathering and interpretation of knowledge.
45. The following inductive statement illustrates the problem of interpreting past data literally, without methodology or logic:
> I have just completed a thorough statistical examination of the life of President Bush. For fifty-eight years, close to 21,000 observations, he did not die once. I can hence pronounce him as immortal, with a high degree of statistical significance.
46. Reality does not have the same closed and symmetric laws and regulations as games.
47. Markets (and life) are not simple win/lose types of situations, as the cost of the losses can be markedly different from that of the wins. Maximizing the probability of winning does not lead to maximizing the expectation from the game when one’s strategy may include skewness, i.e., a small chance of a large loss and a large chance of a small win.
48. One cannot infer much from a single experiment in a random environment — an experiment needs repeatability showing some causal component.
49. There are only two types of theories:
    * Theories that are known to be wrong, as they were tested and adequately rejected (he calls them falsified).
    * Theories that have not yet been known to be wrong, not falsified yet, but are exposed to be proved wrong.
50. A theory that does not present a set of conditions under which it would be considered wrong would be termed charlatanism — it would be impossible to reject otherwise.
51. An open society is one in which no permanent truth is held to exist; this would allow counter-ideas to emerge.
52. We like to emit logical and rational ideas but we do not necessarily enjoy this execution.
53. Induction is going from plenty of particulars to the general.
54. We tend to mistake one realization among all possible random histories as the most representative one, forgetting that there may be others. In a nutshell, the **survivorship bias** implies that the highest-performing realization will be the most visible. Why? Because the losers do not show up.
55.  A population entirely composed of bad managers will still produce a small amount of great track records.
56. The number of managers with great track records in a given market depends far more on the number of people who started in the investment business, rather than on their ability to produce profits. It also depends on the volatility.
57. It is very likely in a large sample of players for one of them to have an inordinately lengthy lucky streak. It is very unlikely that an unspecified player somewhere does not have an inordinately lengthy lucky streak.
58. Judging an investment that comes to you requires more stringent standards than judging an investment you seek, owing to such **selection bias**.
59. There is a high probability of the investment coming to you if its success is caused entirely by randomness.
60. The distribution of the maximum of a variable is different from that of the variable itself.
61. There is no true attainable randomness in practice, only in theory.
62. A single random run is bound to exhibit some pattern — if one looks hard enough.
63. Real randomness does not look random.
64. Science is marred by a pernicious survivorship bias, affecting the way research gets published. In a way that is similar to journalism, research that yields no result does not make it to print.
65. A finding of absence (evidence of absence) and an absence of findings (absence of evidence) get mixed together.
66. Path dependence is the dependence of economic outcomes on the path of previous outcomes, rather than simply on current conditions. In a path-dependent process, “history matters” — it has an enduring influence. Choices made based on transitory conditions can persist long after those conditions change.
67. Our brain is not cut out for nonlinearities. People think that if, say, two variables are causally linked, then a steady input in one variable should always yield a result in the other one.
68. Rules have their value. We just follow them not because they are the best but because they are useful and they save time and effort.
    >  Consider that those who started theorizing upon seeing a tiger on whether the tiger was of this or that taxonomic variety, and the degree of danger it represented, ended up being eaten by it. Others who just ran away at the smallest presumption and were not slowed down by the smallest amount of thinking ended up either out chasing the tiger or out chasing their cousin who ended up being eaten by it.
69. The availability heuristic: corresponds to the practice of estimating the frequency of an event according to the ease with which instances of the event can be recalled.
70. The representativeness heuristic: gauging the probability that a person belongs to a particular social group by assessing how similar the person’s characteristics are to the “typical” group member’s.
71. The simulation heuristic: the ease of mentally undoing an event — playing the alternative scenario. It corresponds to counterfactual thinking: Imagine what might have happened had you not missed your train.
72. The affect heuristic: What emotions are elicited by events determine their probability in your mind.
73. One cannot decide without emotion. Now, mathematics gives the same answer: If one were to perform an optimizing operation across a large collection of variables, even with a brain as large as ours, it would take a very long time to decide on the simplest of tasks. So we need a shortcut; emotions are there to prevent us from temporizing.
74. People overvalue their knowledge and underestimate the probability of their being wrong.
75. By a law of probability called distribution of the maximum of random variables, the maximum of an average is necessarily less volatile than the average maximum.
76. At birth, your unconditional life expectancy may be seventy-three years. But as you advance in age and do not die, your life expectancy increases along with your life. Why? Because other people, by dying, have taken your spot in the statistics, for expectation means average. So if you are seventy-three and are in good health, you may still have, say, nine years in expectation. But the expectation would change, and at eighty-two, you will have another five years, provided of course you are still alive. Even someone one hundred years old still has positive conditional life expectation.
77. Such a statement, when one thinks about it, is not too different from the one that says: Our operation has a mortality rate of 1%. So far we have operated on ninety-nine patients with great success; you are our one hundredth hence you have a 100% probability of dying on the table.
78. ￼Conditional information: Unless the source of the statement has extremely high qualifications, the statement will be more revealing of the author than the information intended by him.
79. Wittgenstein’s ruler: Unless have confidence in the ruler’s reliability, if you use a ruler to measure a table you may also be using the table to measure the ruler. The less you trust the ruler’s reliability (in probability called the prior), the more information you are getting about the ruler and the less about the table.
80. The skeptics’ main teaching was that nothing could be accepted with certainty, conclusions of various degrees of probability could be formed, and these supplied a guide to conduct.
81. Self-contradiction is made culturally to be shameful, a matter that can prove disastrous in science.
82. We have been getting things wrong in the past and we laugh at our past institutions; it is time to figure out that we should avoid enshrining the present ones.
83. Science is great, but individual scientists are dangerous.
84. The higher up the corporate ladder, the higher the compensation to the individual. This might be justified, as it makes plenty of sense to pay individuals according to their contributions. However, and in general (provided we exclude risk-bearing entrepreneurs), the higher up the corporate ladder, the lower the evidence of such contribution.
85. To view it in another way, consider the difference between judging on process and judging on results. Lower-ranking persons in the enterprise are on both process and results — in fact, owing to the repetitive aspect of their efforts, their process converges rapidly to results. But top management is only paid on results —no matter the process. There seems to be no such thing as a foolish decision if it results in profits.
86. Repetitiveness is key for the revelation of skills.
87. We attribute heroism to those who took crazy decisions but were lucky enough to win — we continue to worship those who won battles and despise those who lost, no matter the reason.
88. What is random and what you do not know are functionally the same.
89. Unpredictability is a strong deterrent.